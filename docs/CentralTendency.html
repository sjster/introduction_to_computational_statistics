
<!DOCTYPE html>

<html xmlns="http://www.w3.org/1999/xhtml">
  <head>
    <meta charset="utf-8" />
    <title>Distributions, Central Tendency, and Shape Parameters &#8212; Introduction to Computational Statistics with PyMC3</title>
    
  <link rel="stylesheet" href="../_static/css/index.73d71520a4ca3b99cfee5594769eaaae.css">

    
  <link rel="stylesheet"
    href="../_static/vendor/fontawesome/5.13.0/css/all.min.css">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">

    
      
  <link rel="stylesheet"
    href="../_static/vendor/open-sans_all/1.44.1/index.css">
  <link rel="stylesheet"
    href="../_static/vendor/lato_latin-ext/1.44.1/index.css">

    
    <link rel="stylesheet" href="../_static/sphinx-book-theme.40e2e510f6b7d1648584402491bb10fe.css" type="text/css" />
    <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
    <link rel="stylesheet" type="text/css" href="../_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/mystnb.css" />
    <link rel="stylesheet" type="text/css" href="../_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="../_static/panels-main.c949a650a448cc0ae9fd3441c0e17fb0.css" />
    <link rel="stylesheet" type="text/css" href="../_static/panels-variables.06eb56fa6e07937060861dad626602ad.css" />
    
  <link rel="preload" as="script" href="../_static/js/index.3da636dd464baa7582d2.js">

    <script id="documentation_options" data-url_root="../" src="../_static/documentation_options.js"></script>
    <script src="../_static/jquery.js"></script>
    <script src="../_static/underscore.js"></script>
    <script src="../_static/doctools.js"></script>
    <script src="../_static/language_data.js"></script>
    <script src="../_static/togglebutton.js"></script>
    <script src="../_static/clipboard.min.js"></script>
    <script src="../_static/copybutton.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
    <script >var togglebuttonSelector = '.toggle, .admonition.dropdown, .tag_hide_input div.cell_input, .tag_hide-input div.cell_input, .tag_hide_output div.cell_output, .tag_hide-output div.cell_output, .tag_hide_cell.cell, .tag_hide-cell.cell';</script>
    <script src="../_static/sphinx-book-theme.d31b09fe5c1d09cb49b26a786de4a05d.js"></script>
    <script async="async" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/latest.js?config=TeX-AMS-MML_HTMLorMML"></script>
    <script type="text/x-mathjax-config">MathJax.Hub.Config({"tex2jax": {"inlineMath": [["\\(", "\\)"]], "displayMath": [["\\[", "\\]"]], "processRefs": false, "processEnvironments": false}})</script>
    <script async="async" src="https://unpkg.com/thebelab@latest/lib/index.js"></script>
    <script >
        const thebe_selector = ".thebe,.cell"
        const thebe_selector_input = "pre,.cell_input div.highlight"
        const thebe_selector_output = ".output,.cell_output"
    </script>
    <script async="async" src="../_static/sphinx-thebe.js"></script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="Parameter Estimation" href="ParameterEstimation.html" />
    <link rel="prev" title="Foundations of Probability" href="Foundations.html" />

    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="docsearch:language" content="en" />



  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="80">
    

    <div class="container-xl">
      <div class="row">
          
<div class="col-12 col-md-3 bd-sidebar site-navigation show" id="site-navigation">
    
        <div class="navbar-brand-box">
<a class="navbar-brand text-wrap" href="../index.html">
  
  <img src="../_static/logo_large.png" class="logo" alt="logo">
  
  
  <h1 class="site-logo" id="site-title">Introduction to Computational Statistics with PyMC3</h1>
  
</a>
</div><form class="bd-search d-flex align-items-center" action="../search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search this book..." aria-label="Search this book..." autocomplete="off" >
</form>
<nav class="bd-links" id="bd-docs-nav" aria-label="Main navigation">
    <p class="caption collapsible-parent">
 <span class="caption-text">
  Getting started
 </span>
</p>
<ul class="nav sidenav_l1">
 <li class="toctree-l1">
  <a class="reference internal" href="getting_started.html">
   Setting up Your Python Environment
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="Databricks.html">
   Introduction to the Databricks Environment
  </a>
 </li>
</ul>
<p class="caption collapsible-parent">
 <span class="caption-text">
  Introduction to Bayesian Statistics
 </span>
</p>
<ul class="current nav sidenav_l1">
 <li class="toctree-l1">
  <a class="reference internal" href="Foundations.html">
   Foundations of Probability
  </a>
 </li>
 <li class="toctree-l1 current active">
  <a class="current reference internal" href="#">
   Distributions, Central Tendency, and Shape Parameters
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="ParameterEstimation.html">
   Parameter Estimation
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="Bayes.html">
   Introduction to the Bayes Theorem
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="Decisions.html">
   Inference and Decisions
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="Priors.html">
   Priors
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="Intro.html">
   Bayesian vs. Frequentist Statistics
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="Distributions.html">
   Introduction to Common Distributions
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="Sampling.html">
   Sampling Strategies
  </a>
 </li>
</ul>
<p class="caption collapsible-parent">
 <span class="caption-text">
  Introduction to Monte Carlo Methods
 </span>
</p>
<ul class="nav sidenav_l1">
 <li class="toctree-l1">
  <a class="reference internal" href="BayesianInference.html">
   Topics in Model Performance
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="MonteCarlo.html">
   Introduction to Monte Carlo Methods
  </a>
 </li>
</ul>
<p class="caption collapsible-parent">
 <span class="caption-text">
  PyMC3 for Bayesian Modeling and Inference
 </span>
</p>
<ul class="nav sidenav_l1">
 <li class="toctree-l1">
  <a class="reference internal" href="PyMC3.html">
   Introduction to PyMC3
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="Reparameterization.html">
   Reparameterization
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="Covid_modeling.html">
   Covid Modeling with PyMC3
  </a>
 </li>
</ul>

</nav> <!-- To handle the deprecated key -->

<div class="navbar_extra_footer">
  Powered by <a href="https://jupyterbook.org">Jupyter Book</a>
</div>

</div>


          


          
<main class="col py-md-3 pl-md-4 bd-content overflow-auto" role="main">
    
    <div class="row topbar fixed-top container-xl">
    <div class="col-12 col-md-3 bd-topbar-whitespace site-navigation show">
    </div>
    <div class="col pl-2 topbar-main">
        
        <button id="navbar-toggler" class="navbar-toggler ml-0" type="button" data-toggle="collapse"
            data-toggle="tooltip" data-placement="bottom" data-target=".site-navigation" aria-controls="navbar-menu"
            aria-expanded="true" aria-label="Toggle navigation" aria-controls="site-navigation"
            title="Toggle navigation" data-toggle="tooltip" data-placement="left">
            <i class="fas fa-bars"></i>
            <i class="fas fa-arrow-left"></i>
            <i class="fas fa-arrow-up"></i>
        </button>
        
        
<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn" aria-label="Download this page"><i
            class="fas fa-download"></i></button>

    <div class="dropdown-buttons">
        <!-- ipynb file if we had a myst markdown file -->
        
        <!-- Download raw file -->
        <a class="dropdown-buttons" href="../_sources/docs/CentralTendency.ipynb"><button type="button"
                class="btn btn-secondary topbarbtn" title="Download source file" data-toggle="tooltip"
                data-placement="left">.ipynb</button></a>
        <!-- Download PDF via print -->
        <button type="button" id="download-print" class="btn btn-secondary topbarbtn" title="Print to PDF"
            onClick="window.print()" data-toggle="tooltip" data-placement="left">.pdf</button>
    </div>
</div>

        <!-- Source interaction buttons -->


        <!-- Full screen (wrap in <a> to have style consistency -->
        <a class="full-screen-button"><button type="button" class="btn btn-secondary topbarbtn" data-toggle="tooltip"
                data-placement="bottom" onclick="toggleFullScreen()" aria-label="Fullscreen mode"
                title="Fullscreen mode"><i
                    class="fas fa-expand"></i></button></a>

        <!-- Launch buttons -->

<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn"
        aria-label="Launch interactive content"><i class="fas fa-rocket"></i></button>
    <div class="dropdown-buttons">
        
        <a class="binder-button" href="https://mybinder.org/v2/gh/sjster/statistical_computing_book/master?urlpath=tree/mini_book/docs/CentralTendency.ipynb"><button type="button"
                class="btn btn-secondary topbarbtn" title="Launch Binder" data-toggle="tooltip"
                data-placement="left"><img class="binder-button-logo"
                    src="../_static/images/logo_binder.svg"
                    alt="Interact on binder">Binder</button></a>
        
        
        
        <a class="colab-button" href="https://colab.research.google.com/github/sjster/statistical_computing_book/blob/master/mini_book/docs/CentralTendency.ipynb"><button type="button" class="btn btn-secondary topbarbtn"
                title="Launch Colab" data-toggle="tooltip" data-placement="left"><img class="colab-button-logo"
                    src="../_static/images/logo_colab.png"
                    alt="Interact on Colab">Colab</button></a>
        
        <button type="button" class="btn btn-secondary topbarbtn"
            onclick="initThebeSBT()" title="Launch Thebe" data-toggle="tooltip" data-placement="left"><i
                class="fas fa-play"></i><span style="margin-left: .4em;">Live Code</span></button>
        
    </div>
</div>

    </div>

    <!-- Table of contents -->
    <div class="d-none d-md-block col-md-2 bd-toc show">
        
        <div class="tocsection onthispage pt-5 pb-3">
            <i class="fas fa-list"></i> Contents
        </div>
        <nav id="bd-toc-nav">
            <ul class="nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#probability-distributions">
   Probability distributions
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#discrete-random-variables">
   Discrete random variables
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#continuous-random-variables">
   Continuous random variables
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#moments-expectations-and-variances">
   Moments, expectations and variances
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#expectation">
   Expectation
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#variance-skewness-kurtosis">
   Variance, skewness, kurtosis
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#properties-of-mean-and-variance">
   Properties of mean and variance
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#other-measures">
   Other measures
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#joint-distributions">
   Joint distributions
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#marginal-distribution">
     Marginal distribution
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#conditional-distributions">
     Conditional distributions
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#independence">
     Independence
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#covariance">
     Covariance
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#correlation-correlation-coefficient">
     Correlation (correlation coefficient)
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#ungraded-evaluation-20-min">
   UNGRADED EVALUATION (20 min)
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#graded-evaluation-15-mins">
   GRADED EVALUATION (15 mins)
  </a>
 </li>
</ul>

        </nav>
        
    </div>
</div>
    <div id="main-content" class="row">
        <div class="col-12 col-md-9 pl-md-3 pr-md-0">
        
              <div>
                
  <div class="section" id="distributions-central-tendency-and-shape-parameters">
<h1>Distributions, Central Tendency, and Shape Parameters<a class="headerlink" href="#distributions-central-tendency-and-shape-parameters" title="Permalink to this headline">¶</a></h1>
<p>In the last video, we discussed sample spaces, events and probability spaces.  We looked at rules for addition and multiplication of probabilities which follow directly from the Axioms of Probability (Kologomorov Axioms).  Here we will continue and extend that discussion to probability distributions and descriptions of those distributions.</p>
<p>Our topics include:</p>
<ol class="simple">
<li><p>probability distributions (discrete vs continuous, pmf vs pdf).</p></li>
<li><p>moments, expectations and variances.</p></li>
<li><p>joint distributions, expectations and covariances with 2 variables.</p></li>
<li><p>marginals.</p></li>
</ol>
<p>General references:</p>
<ul class="simple">
<li><p>Statistical Inference (9780534243128): Casella, George, Berger, Roger L.</p></li>
<li><p>Probability Theory and Statistical Inference: Empirical Modeling with Observational Data (9781107185142): Spanos, A.</p></li>
<li><p>Bayesian Models: A Statistical Primer for Ecologists (9780691159287): Hobbs, N. Thompson, Hooten, Mevin B.</p></li>
<li><p>A First Course in Bayesian Statistical Methods (0387922997): Hoff, Peter D.</p></li>
</ul>
<br>
<br>
<hr style="border:2px solid blue"> </hr><div class="section" id="probability-distributions">
<h2>Probability distributions<a class="headerlink" href="#probability-distributions" title="Permalink to this headline">¶</a></h2>
<p>As a reminder, last time we had introduced the concept of a probability space as a combination of a sample space, event space, and probability function.  The probability function is a real-valued function mapping events to the interval [0,1].  The probability function adheres to the Axioms of Probability (Kolmogorov Axioms).  These are summarized as:</p>
<ol>
<li><p>the probability of an event is a real number on the interval [0,1]</p>
<p><span class="math notranslate nohighlight">\(0 \le P(E) \le 1\)</span><br />
<br></p>
</li>
<li><p>the probability of at least one event occuring is 1</p>
<p><span class="math notranslate nohighlight">\(P(S) = 1\)</span>, where S is the sample space<br />
<br></p>
</li>
<li><p>countable mutually exclusive sets of events satisfy the following</p>
<p><span class="math notranslate nohighlight">\(P(\bigcup_{i=1}^\infty E_i) = \sum_{i=1}^\infty P(E_i)\)</span></p>
</li>
</ol>
<p>In addition to the probability space, we talked about random variables being (often) real-valued functions mapping outcomes (events) to a measureable space.  In set notation, this looks like:</p>
<p><span class="math notranslate nohighlight">\(X: \Omega \to \mathbb{R}\)</span></p>
<p>Combining the mapping of events with the association of the probability function, we have what we need to study random processes.  This mapping defines the probability given by X in a measureable set as:</p>
<p><span class="math notranslate nohighlight">\(P(X \in S) = P({x \in \Omega | X(x) \in S})\)</span></p>
<p>For example, consider the case of tossing two fair coins where we are interested in the events being {(HH),(TT)} or not.  Our sample space is:</p>
<p>S = {(HH),(TT),(TH),(HT)}</p>
<p>Our event space is:</p>
<p><span class="math notranslate nohighlight">\(\mathcal{F}\)</span> = {S, <span class="math notranslate nohighlight">\(\bar{S}\)</span>, E, <span class="math notranslate nohighlight">\(\bar{E}\)</span> }, E = {(HH),(TT)}</p>
<p>where we have defined X(HH)=X(TT)=1, 0 otherwise, which leads us to:</p>
<p><span class="math notranslate nohighlight">\(P_X(x) = 
\begin{cases}
    \frac{1}{2}, \text{for x = 1} \\
    \frac{1}{2}, \text{for x = 0} \\
\end{cases}
\)</span></p>
<p>We now have our first random variable which happens to be distributed according to the Bernoulli distribution more generally written as:</p>
<p><span class="math notranslate nohighlight">\(X \sim Bern(\theta)\)</span>, where</p>
<p><span class="math notranslate nohighlight">\(f(x;\theta) = P(X=x;\theta) =
\begin{cases}
    \theta, \text{for x = 1} \\
    1 - \theta, \text{for x = 0} \\
\end{cases}
\)</span></p>
<p>or</p>
<p><span class="math notranslate nohighlight">\(f(x;\theta) = \theta^x(1-\theta)^{(1-x)}\)</span></p>
<p>For <span class="math notranslate nohighlight">\(\theta\)</span> = [0,1].  Distributions are associated with parameters.  As defined above, we see <span class="math notranslate nohighlight">\(\theta\)</span> as the <strong>parameter</strong> associated with the Bernoulli distribution is the probability of success.</p>
<br>
<br>
<hr style="border:2px solid blue"> </hr>
</div>
<div class="section" id="discrete-random-variables">
<h2>Discrete random variables<a class="headerlink" href="#discrete-random-variables" title="Permalink to this headline">¶</a></h2>
<p>As above, discrete random variables are characterized by countable outcome spaces.  Discrete random variables are associated with a <strong>probability mass function (pmf)</strong> whose range is a countable subset of <span class="math notranslate nohighlight">\(\mathbb{R}\)</span> with probability values in the range [0,1].  Properties of the pmf include:</p>
<ol class="simple">
<li><p><span class="math notranslate nohighlight">\(f_x(x) \ge 0\)</span>, for all <span class="math notranslate nohighlight">\(x \in \mathbb{R}_X\)</span>.</p></li>
<li><p><span class="math notranslate nohighlight">\(\sum_{x \in X} f_x(x) = 1\)</span></p></li>
<li><p><span class="math notranslate nohighlight">\(F_X(b) - F_X(a) = \sum_{x=a}^b f(x), a &lt; b, a, b \in \mathbb{R}\)</span></p></li>
</ol>
<p>The last property involves the cdf (cumulative distribution function).  The cdf is defined such that:</p>
<p><span class="math notranslate nohighlight">\(F_X(b) = \sum_{x \in [-\infty,b]} f_X(x)\)</span></p>
<p>Which, with some thought, we could come up with the properties of the cdf:</p>
<ol class="simple">
<li><p>non-decreasing: <span class="math notranslate nohighlight">\(F_X(x) \le F_X(y)\)</span>, for all <span class="math notranslate nohighlight">\(x \le y\)</span></p></li>
<li><p>right-continuous: <span class="math notranslate nohighlight">\(\lim_{x \downarrow x_0^+} F_X(x) = F_X(x_0)\)</span></p></li>
<li><p>positive, with range [0,1]</p></li>
</ol>
<p>For discrete variables, <span class="math notranslate nohighlight">\(F_X(x) = P(X \le x) = \sum_{x_i \le x}f(x_i)\)</span></p>
<br>
<br>
<hr style="border:2px solid blue"> </hr></div>
<div class="section" id="continuous-random-variables">
<h2>Continuous random variables<a class="headerlink" href="#continuous-random-variables" title="Permalink to this headline">¶</a></h2>
<p>In the discrete case, random variables are characterized by countable outcome spaces where the random variable maps events to discrete values on <span class="math notranslate nohighlight">\(\mathbb{R}\)</span>.  How do we deal with outcome spaces that are continuous?  We use intervals.</p>
<p>Continuous random variables are associated with a <strong>probability density function (pdf)</strong> whose range is an uncountable subset of <span class="math notranslate nohighlight">\(\mathbb{R}\)</span> with probability values in the range [0,<span class="math notranslate nohighlight">\(\infty\)</span>].  Properties of the pdf include:</p>
<ol class="simple">
<li><p><span class="math notranslate nohighlight">\(f_x(x) \ge 0\)</span>, for all <span class="math notranslate nohighlight">\(x \in \mathbb{R}_X\)</span>.</p></li>
<li><p><span class="math notranslate nohighlight">\(\int_{-\infty}^\infty f_x(x)dx = 1\)</span></p></li>
<li><p><span class="math notranslate nohighlight">\(F_X(b) - F_X(a) = \int_{a}^b f(x)dx,\ a &lt; b, (a, b) \in \mathbb{R}\)</span></p></li>
</ol>
<p>Note, the cdf of a continuous random variable is generally defined as:
<span class="math notranslate nohighlight">\(P(X \le x) = F_X(x) = \int_{-\infty}^x f(u)du\)</span> where we can we can recover the pdf via <span class="math notranslate nohighlight">\(f(x) = \frac{dF(x)}{dx}\)</span>.  The properties of the continuous cdf are obvious extensions of the discrete case.  One difference we sometimes overlook is the <span class="math notranslate nohighlight">\(P(X=x)=0\)</span> AND in the continuous case because <span class="math notranslate nohighlight">\(x\)</span> is a point value.  To solve this conundrum, we we use intervals, ie area under the curve when talking probabilities.</p>
<p>Arguably, the most widely studied and used distribution in statistics is the normal distribution.  The pdf of the normal distribution is given as</p>
<p><span class="math notranslate nohighlight">\(X \sim Norm(\mu,\sigma^2)\)</span> , where</p>
<p><span class="math notranslate nohighlight">\(f_x(x,\mu,\sigma^2) = \frac{1}{\sqrt{2\pi\sigma^2}}e^{-\frac{(x-\mu)^2}{2\sigma^2}}\)</span>, <span class="math notranslate nohighlight">\(\text{ where } (x,\mu,\sigma^2) \in (\mathbb{R},\mathbb{R},\mathbb{R}_+)\)</span></p>
<p>A plot of the normal pdf is show below. Where we are setting <span class="math notranslate nohighlight">\(\mu = 0\)</span> and <span class="math notranslate nohighlight">\(\sigma^2=1\)</span>.  Note, the <strong>parameters</strong> of the distribution as given are <span class="math notranslate nohighlight">\(\mu\)</span> and <span class="math notranslate nohighlight">\(\sigma^2\)</span>.  The parameters of the normal distribution describe the location and shape: <span class="math notranslate nohighlight">\(\mu\)</span> gives the center of mass while <span class="math notranslate nohighlight">\(\sigma^2\)</span> gives and indication of spread.</p>
<br>
<br>
<hr style="border:2px solid blue"> </hr><div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">scipy.stats</span> <span class="k">as</span> <span class="nn">stats</span>
<span class="kn">import</span> <span class="nn">math</span>

<span class="n">mu</span> <span class="o">=</span> <span class="mi">0</span>
<span class="n">variance</span> <span class="o">=</span> <span class="mi">1</span>
<span class="n">sigma</span> <span class="o">=</span> <span class="n">math</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">variance</span><span class="p">)</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="n">mu</span> <span class="o">-</span> <span class="mi">3</span><span class="o">*</span><span class="n">sigma</span><span class="p">,</span> <span class="n">mu</span> <span class="o">+</span> <span class="mi">3</span><span class="o">*</span><span class="n">sigma</span><span class="p">,</span> <span class="mi">100</span><span class="p">)</span> <span class="c1">#bounds and granularity</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">stats</span><span class="o">.</span><span class="n">norm</span><span class="o">.</span><span class="n">pdf</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">mu</span><span class="p">,</span> <span class="n">sigma</span><span class="p">))</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../_images/CentralTendency_4_0.png" src="../_images/CentralTendency_4_0.png" />
</div>
</div>
</div>
<div class="section" id="moments-expectations-and-variances">
<h2>Moments, expectations and variances<a class="headerlink" href="#moments-expectations-and-variances" title="Permalink to this headline">¶</a></h2>
<p>Distributions are recognizable by characteristics such as range, location and shape.  Computing moments such as expectation, variance, skewness and kurtosis can be used to estimate the parameters that define a distribution.</p>
</div>
<div class="section" id="expectation">
<h2>Expectation<a class="headerlink" href="#expectation" title="Permalink to this headline">¶</a></h2>
<p>The expectation of a function is the average value of the function under a probability distribution.  In the case of discrete distributions, this is computed as the weighted average where the weights are dictated by the probability at the value of x (where p(x) is the pmf/pdf):</p>
<p><span class="math notranslate nohighlight">\(E[f] = \sum_x f(x)^r p(x)\)</span></p>
<p>For continuous distributions, this looks like</p>
<p><span class="math notranslate nohighlight">\(E[f] = \int f(x)^r p(x) dx.\)</span></p>
<p>if <span class="math notranslate nohighlight">\(f(x) = x\)</span> and <span class="math notranslate nohighlight">\(r=1\)</span> in both cases (discrete and continuous), this is called the mean of the distribution.  In the figure of the normal distribution above, computing the expectation will give <span class="math notranslate nohighlight">\(E[x]=0\)</span> which matches our intuition of where the bulk of the mass is centered based on the figure.</p>
<p>For the Bernoulli distribution given earlier, we compute this as</p>
<p><span class="math notranslate nohighlight">\(E[x] = \sum_{x=0,1} x\ast p(x,\theta) = 0\ast(1-\theta) + 1\ast\theta = \theta\)</span></p>
<p>Thus, for the Bernoulli distribution, the mean is equal to the parameter for success, <span class="math notranslate nohighlight">\(E[x]_{Bern} = \theta\)</span>.</p>
</div>
<div class="section" id="variance-skewness-kurtosis">
<h2>Variance, skewness, kurtosis<a class="headerlink" href="#variance-skewness-kurtosis" title="Permalink to this headline">¶</a></h2>
<p>While the mean of the distribution, also the first raw moment, is given by the first power of <span class="math notranslate nohighlight">\(x^1\)</span>, other interesting moments arrise when we take powers of <span class="math notranslate nohighlight">\(X-E[X]\)</span>.</p>
<p>Variance, measures spread of the distribution:<br />
<span class="math notranslate nohighlight">\(Var(X) = E[(X-E[X])^2] = \int (X-E[X])^2 p(x) dx\)</span> in the continuous case.</p>
<p>Skewness, measures symmetry:<br />
<span class="math notranslate nohighlight">\(\alpha_3 = \frac{E(X-E[X])^3}{(\sqrt{Var(X)})^3}\)</span></p>
<p>Kurtosis, measures “peakiness”:<br />
<span class="math notranslate nohighlight">\(\alpha_4 = \frac{E(X-E[X])^4}{(\sqrt{Var(X)})^4}\)</span></p>
</div>
<div class="section" id="properties-of-mean-and-variance">
<h2>Properties of mean and variance<a class="headerlink" href="#properties-of-mean-and-variance" title="Permalink to this headline">¶</a></h2>
<p>Expectation is a linear operator.  As such, we can easily prove the following useful properties:</p>
<ol class="simple">
<li><p><span class="math notranslate nohighlight">\(E[c] = c\)</span>, where c is a constant.</p></li>
<li><p><span class="math notranslate nohighlight">\(E[aX_1 + bX_2] = aE[X_1] + bE[X_2]\)</span></p></li>
</ol>
<p>Similarly, with variance:</p>
<ol class="simple">
<li><p><span class="math notranslate nohighlight">\(Var(X) = E[(X-E[X])^2] = E[X^2] - (E[X])^2\)</span></p></li>
<li><p><span class="math notranslate nohighlight">\(Var(c) = 0\)</span>, where c is a constant.</p></li>
<li><p><span class="math notranslate nohighlight">\(Var(aX_1 + bX_2) = a^2Var(X_1) + b^2Var(X_2)\)</span></p></li>
</ol>
<p>Standard deviation is defined as <span class="math notranslate nohighlight">\(\sigma = \sqrt{Var(X)}\)</span>.  This is a useful quantity as it is on the same scale as X.</p>
</div>
<div class="section" id="other-measures">
<h2>Other measures<a class="headerlink" href="#other-measures" title="Permalink to this headline">¶</a></h2>
<p>Mode – most frequent value.
<span class="math notranslate nohighlight">\(\frac{df(x)}{dx}=0\)</span> needs to be max.</p>
<p>Median – middle value, place where probability is equal to right/left.
<span class="math notranslate nohighlight">\(P(X &lt; x) = P(X &gt; x) = 1/2\)</span></p>
<p>Quantiles are defined using the cdf.
<span class="math notranslate nohighlight">\(F_X(x) \ge p\)</span></p>
<p>For the normal distribution, mean = median = mode.</p>
<br>
<br>
<hr style="border:2px solid blue"> </hr></div>
<div class="section" id="joint-distributions">
<h2>Joint distributions<a class="headerlink" href="#joint-distributions" title="Permalink to this headline">¶</a></h2>
<p>In many cases, we will be working on distributions of more than one variable.  These are termed joint distributions.  These joint distributions can be of mixed type, e.g. Bernoulli and normal, normal and Cauchy, etc.  These can be thought of in the normal way:</p>
<p><span class="math notranslate nohighlight">\(P_{XY}(x,y) = P(X=x,Y=y)\)</span></p>
<p>We often want to determine a parameter in a distribution of more than one variable.  For instance, the expectation of <span class="math notranslate nohighlight">\(f(x,y)\)</span></p>
<p><span class="math notranslate nohighlight">\(E[f(x,y)] = \int_{x,y} f(x,y) p(x,y) dxdy\)</span></p>
<p>where <span class="math notranslate nohighlight">\(f(x,y)=xy\)</span> would give the mean analogous to the univariate case.</p>
<div class="section" id="marginal-distribution">
<h3>Marginal distribution<a class="headerlink" href="#marginal-distribution" title="Permalink to this headline">¶</a></h3>
<p>In cases where we have a joint distribution, we will sometimes need to find the marginal distribution.  The marginial distribution for a case where we have a joint distribution of X and Y is:</p>
<p><span class="math notranslate nohighlight">\(P_X(x) = \sum_{all y_i} P_{XY}(x,y_i)\)</span> and similarly for the marginal in Y.  The extension to a continuous case or mixed case is an obvious use of an integral.</p>
<p>Intuitively, we are integrating (or averaging) out the effect of R.V. Y to get at the marginal distribution of X.</p>
</div>
<div class="section" id="conditional-distributions">
<h3>Conditional distributions<a class="headerlink" href="#conditional-distributions" title="Permalink to this headline">¶</a></h3>
<p>Remember our rules of probabillity …</p>
<p><span class="math notranslate nohighlight">\(P_{XY}(x_i|y_j) = \frac{P_{XY}(x_i,y_j)}{P_Y(y_i)}\)</span></p>
<p>The conditional expectation is given by</p>
<p><span class="math notranslate nohighlight">\(E[X|Y=y_j] = \sum_{X} x_iP_{X|Y}(x_i|y_j)\)</span></p>
<p>or in the continuous case for a function g:</p>
<p><span class="math notranslate nohighlight">\(E[g(Y)|x] = \int_{-\infty}^{\infty} g(y)f(y|x)dy\)</span></p>
</div>
<div class="section" id="independence">
<h3>Independence<a class="headerlink" href="#independence" title="Permalink to this headline">¶</a></h3>
<p>It can be shown that if X and Y are independent, there exists some functions g(x) and h(y) such that:</p>
<p><span class="math notranslate nohighlight">\(f(x,y) = g(x)h(y)\)</span> for all (x,y)</p>
<p>How do we use this?  In the discrete case, if we can find a pair (x,y) that violate the product rule, the random variables are dependent.</p>
</div>
<div class="section" id="covariance">
<h3>Covariance<a class="headerlink" href="#covariance" title="Permalink to this headline">¶</a></h3>
<p><span class="math notranslate nohighlight">\(cov[x,y] = E[(x-E[x])(y-E[y])] = E_{x,y}[xy]-E_x[x]E_y[y]\)</span></p>
</div>
<div class="section" id="correlation-correlation-coefficient">
<h3>Correlation (correlation coefficient)<a class="headerlink" href="#correlation-correlation-coefficient" title="Permalink to this headline">¶</a></h3>
<p>The correlation coefficient gives an indication of how much or little X,Y vary together.  If X,Y are independent, <span class="math notranslate nohighlight">\(cov(X,Y)= corr(X,Y) = 0\)</span>.  Correlary is not true.
<span class="math notranslate nohighlight">\(\rho_{XY} = \frac{Cov(X,Y)}{\sigma_x\sigma_y}\)</span></p>
</div>
</div>
<div class="section" id="ungraded-evaluation-20-min">
<h2>UNGRADED EVALUATION (20 min)<a class="headerlink" href="#ungraded-evaluation-20-min" title="Permalink to this headline">¶</a></h2>
<ol>
<li><p>Finding the CDF of a distribution</p>
<p><span class="math notranslate nohighlight">\(X\sim exp(\lambda)\)</span></p>
<p>pdf: <span class="math notranslate nohighlight">\(f(x|\lambda) = \lambda e^{-\lambda x}, x,\lambda \in \mathbb{R}_+,\mathbb{R}&gt;0\)</span></p>
<p>Find the cdf of X via integration.</p>
<p>a. <span class="math notranslate nohighlight">\(1-e^{-\lambda}\)</span> (C)</p>
<p>b. <span class="math notranslate nohighlight">\(1+e^{-\lambda}\)</span></p>
</li>
<li><p>Find the expection of a function</p>
<p>Assuming <span class="math notranslate nohighlight">\(X \sim exp(\lambda)\)</span>, find the expection of <span class="math notranslate nohighlight">\(g(x)=x^2\)</span>.</p>
<p>a. <span class="math notranslate nohighlight">\(\frac{1}{\lambda^2}\)</span></p>
<p>b. <span class="math notranslate nohighlight">\(\frac{2}{\lambda^2}\)</span> (C)</p>
</li>
<li><p>Correlation of X and Y equals 0.  Are X and Y independent?</p>
<p>a. yes</p>
<p>b. can’t tell (C)</p>
</li>
</ol>
</div>
<div class="section" id="graded-evaluation-15-mins">
<h2>GRADED EVALUATION (15 mins)<a class="headerlink" href="#graded-evaluation-15-mins" title="Permalink to this headline">¶</a></h2>
<ol>
<li><p>Are X and Y independent?</p>
<p><span class="math notranslate nohighlight">\(f(x,y) = \frac{1}{57}xy^6e^{-y-x},x&gt;0,y&gt;0\)</span></p>
<p>a. True (C)</p>
<p>b. False</p>
</li>
<li><p>The marginal distribution of X</p>
<p><span class="math notranslate nohighlight">\(f(x,y) = 4xy; x,y \in [0,1]\)</span></p>
<p>a. A function of x (C)</p>
<p>b. A function of y</p>
</li>
<li><p>Find the marginal distribution of x in <span class="math notranslate nohighlight">\(f(x,y)\)</span> from the last problem.</p>
<p>a. 2x  (c)</p>
<p>b. 2y</p>
</li>
</ol>
</div>
</div>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "sjster/statistical_computing_book",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            kernelName: "python3",
            path: "./docs"
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

              </div>
              
        </div>
    </div>
    
    
    <div class='prev-next-bottom'>
        
    <a class='left-prev' id="prev-link" href="Foundations.html" title="previous page">Foundations of Probability</a>
    <a class='right-next' id="next-link" href="ParameterEstimation.html" title="next page">Parameter Estimation</a>

    </div>
    <footer class="footer mt-5 mt-md-0">
    <div class="container">
      <p>
        
          By Srijith Rajamohan, Ph.D.<br/>
        
            &copy; Copyright 2020.<br/>
      </p>
    </div>
  </footer>
</main>


      </div>
    </div>

    
  <script src="../_static/js/index.3da636dd464baa7582d2.js"></script>


    
  </body>
</html>