
<!DOCTYPE html>

<html xmlns="http://www.w3.org/1999/xhtml">
  <head>
    <meta charset="utf-8" />
    <title>Sampling Algorithms &#8212; Introduction to Computational Statistics with PyMC3</title>
    
  <link rel="stylesheet" href="../_static/css/index.f658d18f9b420779cfdf24aa0a7e2d77.css">

    
  <link rel="stylesheet"
    href="../_static/vendor/fontawesome/5.13.0/css/all.min.css">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">

    
      
  <link rel="stylesheet"
    href="../_static/vendor/open-sans_all/1.44.1/index.css">
  <link rel="stylesheet"
    href="../_static/vendor/lato_latin-ext/1.44.1/index.css">

    
    <link rel="stylesheet" href="../_static/sphinx-book-theme.40e2e510f6b7d1648584402491bb10fe.css" type="text/css" />
    <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
    <link rel="stylesheet" type="text/css" href="../_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/mystnb.css" />
    <link rel="stylesheet" type="text/css" href="../_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="../_static/panels-main.c949a650a448cc0ae9fd3441c0e17fb0.css" />
    <link rel="stylesheet" type="text/css" href="../_static/panels-variables.06eb56fa6e07937060861dad626602ad.css" />
    
  <link rel="preload" as="script" href="../_static/js/index.d3f166471bb80abb5163.js">

    <script id="documentation_options" data-url_root="../" src="../_static/documentation_options.js"></script>
    <script src="../_static/jquery.js"></script>
    <script src="../_static/underscore.js"></script>
    <script src="../_static/doctools.js"></script>
    <script src="../_static/language_data.js"></script>
    <script src="../_static/togglebutton.js"></script>
    <script src="../_static/clipboard.min.js"></script>
    <script src="../_static/copybutton.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
    <script >var togglebuttonSelector = '.toggle, .admonition.dropdown, .tag_hide_input div.cell_input, .tag_hide-input div.cell_input, .tag_hide_output div.cell_output, .tag_hide-output div.cell_output, .tag_hide_cell.cell, .tag_hide-cell.cell';</script>
    <script src="../_static/sphinx-book-theme.d31b09fe5c1d09cb49b26a786de4a05d.js"></script>
    <script async="async" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/latest.js?config=TeX-AMS-MML_HTMLorMML"></script>
    <script type="text/x-mathjax-config">MathJax.Hub.Config({"tex2jax": {"inlineMath": [["\\(", "\\)"]], "displayMath": [["\\[", "\\]"]], "processRefs": false, "processEnvironments": false}})</script>
    <script async="async" src="https://unpkg.com/thebelab@latest/lib/index.js"></script>
    <script >
        const thebe_selector = ".thebe,.cell"
        const thebe_selector_input = "pre,.cell_input div.highlight"
        const thebe_selector_output = ".output,.cell_output"
    </script>
    <script async="async" src="../_static/sphinx-thebe.js"></script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="Topics in Model Performance" href="BayesianInference.html" />
    <link rel="prev" title="Introduction to Common Distributions" href="Distributions.html" />

    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="docsearch:language" content="en" />



  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="80">
    

    <div class="container-xl">
      <div class="row">
          
<div class="col-12 col-md-3 bd-sidebar site-navigation show" id="site-navigation">
    
        <div class="navbar-brand-box">
<a class="navbar-brand text-wrap" href="../index.html">
  
  <img src="../_static/logo_large.png" class="logo" alt="logo">
  
  
  <h1 class="site-logo" id="site-title">Introduction to Computational Statistics with PyMC3</h1>
  
</a>
</div><form class="bd-search d-flex align-items-center" action="../search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search this book..." aria-label="Search this book..." autocomplete="off" >
</form>
<nav class="bd-links" id="bd-docs-nav" aria-label="Main navigation">
    <p class="caption collapsible-parent">
 <span class="caption-text">
  Getting started
 </span>
</p>
<ul class="nav sidenav_l1">
 <li class="toctree-l1">
  <a class="reference internal" href="About.html">
   The What, Why and Whom…
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="getting_started.html">
   Setting up Your Python Environment
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="Databricks.html">
   Introduction to the Databricks Environment
  </a>
 </li>
</ul>
<p class="caption collapsible-parent">
 <span class="caption-text">
  Introduction to Bayesian Statistics
 </span>
</p>
<ul class="current nav sidenav_l1">
 <li class="toctree-l1">
  <a class="reference internal" href="Foundations.html">
   Foundations of Probability
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="CentralTendency.html">
   Distributions, Central Tendency, and Shape Parameters
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="ParameterEstimation.html">
   Parameter Estimation
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="Bayes.html">
   Introduction to the Bayes Theorem
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="Decisions.html">
   Inference and Decisions
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="Priors.html">
   Priors
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="Intro.html">
   Bayesian vs. Frequentist Statistics
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="Distributions.html">
   Introduction to Common Distributions
  </a>
 </li>
 <li class="toctree-l1 current active">
  <a class="current reference internal" href="#">
   Sampling Algorithms
  </a>
 </li>
</ul>
<p class="caption collapsible-parent">
 <span class="caption-text">
  Introduction to Monte Carlo Methods
 </span>
</p>
<ul class="nav sidenav_l1">
 <li class="toctree-l1">
  <a class="reference internal" href="BayesianInference.html">
   Topics in Model Performance
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="MonteCarlo.html">
   Introduction to Monte Carlo Methods
  </a>
 </li>
</ul>
<p class="caption collapsible-parent">
 <span class="caption-text">
  PyMC3 for Bayesian Modeling and Inference
 </span>
</p>
<ul class="nav sidenav_l1">
 <li class="toctree-l1">
  <a class="reference internal" href="PyMC3.html">
   Introduction to PyMC3
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="Reparameterization.html">
   Reparameterization
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="Covid_modeling.html">
   Covid Modeling with PyMC3
  </a>
 </li>
</ul>

</nav> <!-- To handle the deprecated key -->

<div class="navbar_extra_footer">
  Powered by <a href="https://jupyterbook.org">Jupyter Book</a>
</div>

</div>


          


          
<main class="col py-md-3 pl-md-4 bd-content overflow-auto" role="main">
    
    <div class="row topbar fixed-top container-xl">
    <div class="col-12 col-md-3 bd-topbar-whitespace site-navigation show">
    </div>
    <div class="col pl-2 topbar-main">
        
        <button id="navbar-toggler" class="navbar-toggler ml-0" type="button" data-toggle="collapse"
            data-toggle="tooltip" data-placement="bottom" data-target=".site-navigation" aria-controls="navbar-menu"
            aria-expanded="true" aria-label="Toggle navigation" aria-controls="site-navigation"
            title="Toggle navigation" data-toggle="tooltip" data-placement="left">
            <i class="fas fa-bars"></i>
            <i class="fas fa-arrow-left"></i>
            <i class="fas fa-arrow-up"></i>
        </button>
        
        
<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn" aria-label="Download this page"><i
            class="fas fa-download"></i></button>

    <div class="dropdown-buttons">
        <!-- ipynb file if we had a myst markdown file -->
        
        <!-- Download raw file -->
        <a class="dropdown-buttons" href="../_sources/docs/Sampling.ipynb"><button type="button"
                class="btn btn-secondary topbarbtn" title="Download source file" data-toggle="tooltip"
                data-placement="left">.ipynb</button></a>
        <!-- Download PDF via print -->
        <button type="button" id="download-print" class="btn btn-secondary topbarbtn" title="Print to PDF"
            onClick="window.print()" data-toggle="tooltip" data-placement="left">.pdf</button>
    </div>
</div>

        <!-- Source interaction buttons -->


        <!-- Full screen (wrap in <a> to have style consistency -->
        <a class="full-screen-button"><button type="button" class="btn btn-secondary topbarbtn" data-toggle="tooltip"
                data-placement="bottom" onclick="toggleFullScreen()" aria-label="Fullscreen mode"
                title="Fullscreen mode"><i
                    class="fas fa-expand"></i></button></a>

        <!-- Launch buttons -->

<div class="dropdown-buttons-trigger">
    <button id="dropdown-buttons-trigger" class="btn btn-secondary topbarbtn"
        aria-label="Launch interactive content"><i class="fas fa-rocket"></i></button>
    <div class="dropdown-buttons">
        
        <a class="binder-button" href="https://mybinder.org/v2/gh/sjster/statistical_computing_book/master?urlpath=tree/mini_book/docs/Sampling.ipynb"><button type="button"
                class="btn btn-secondary topbarbtn" title="Launch Binder" data-toggle="tooltip"
                data-placement="left"><img class="binder-button-logo"
                    src="../_static/images/logo_binder.svg"
                    alt="Interact on binder">Binder</button></a>
        
        
        
        <a class="colab-button" href="https://colab.research.google.com/github/sjster/statistical_computing_book/blob/master/mini_book/docs/Sampling.ipynb"><button type="button" class="btn btn-secondary topbarbtn"
                title="Launch Colab" data-toggle="tooltip" data-placement="left"><img class="colab-button-logo"
                    src="../_static/images/logo_colab.png"
                    alt="Interact on Colab">Colab</button></a>
        
        <button type="button" class="btn btn-secondary topbarbtn"
            onclick="initThebeSBT()" title="Launch Thebe" data-toggle="tooltip" data-placement="left"><i
                class="fas fa-play"></i><span style="margin-left: .4em;">Live Code</span></button>
        
    </div>
</div>

    </div>

    <!-- Table of contents -->
    <div class="d-none d-md-block col-md-2 bd-toc show">
        
        <div class="tocsection onthispage pt-5 pb-3">
            <i class="fas fa-list"></i> Contents
        </div>
        <nav id="bd-toc-nav">
            <ul class="nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#sampling-from-discrete-distributions">
   Sampling from Discrete Distributions
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#uniform-continuous-to-uniform-discrete">
     Uniform Continuous to Uniform Discrete
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#arbitrary-non-uniform-discrete-distributions">
     Arbitrary (Non-uniform) Discrete Distributions
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#the-inverse-transform-method">
   The Inverse Transform Method
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#derivation">
     Derivation
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#algorithm">
     Algorithm
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#example">
     Example
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#ungraded-evaluation-30mins">
   UNGRADED EVALUATION (30mins)
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#graded-evaluation-15-mins">
   GRADED EVALUATION (15 mins)
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#rejection-sampling">
   Rejection Sampling
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#importance-sampling">
   Importance Sampling
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#id1">
   GRADED EVALUATION (15 mins)
  </a>
 </li>
</ul>

        </nav>
        
    </div>
</div>
    <div id="main-content" class="row">
        <div class="col-12 col-md-9 pl-md-3 pr-md-0">
        
              <div>
                
  <div class="section" id="sampling-algorithms">
<h1>Sampling Algorithms<a class="headerlink" href="#sampling-algorithms" title="Permalink to this headline">¶</a></h1>
<p><strong>Reference</strong></p>
<ul class="simple">
<li><p><a class="reference external" href="https://www.wiley.com/en-us/An+Introduction+to+Statistical+Computing%3A+A+Simulation+based+Approach-p-9781118357729">An Introduction to Statistical Computing: A Simulation-based Approach, Jochen Voss</a></p></li>
</ul>
<p>We want to look at ways to sample from a distribution.
In most practical scenarios, the distributions are complex enough that it is difficult enough to sample from appropriately but they can often be evaluated at a certain point. The simple strategy of sampling uniformly fails for a couple of reasons.</p>
<ol class="simple">
<li><p>This quickly becomes inefficient as the number of dimensions grow.</p></li>
<li><p>In high-dimensional spaces, there are vast regions of nothingness and most of the probability density is concentrated in a small region. Ideally, we want to sample from regions in space where the function f(x) and the probability of that value f(x) given by p(x) is high so that the contribution of this term \(f(x) p(x)\) is high.</p></li>
</ol>
<p>We will look at various ways to perform efficient sampling here. This is useful not only to understand how distributions are sampled in practice in a package such as SciPy, but it also helps you to write your own custom distribution should that need arise.</p>
<p>The techniques listed are mostly applicable to univariate distributions, but they are useful to understand since they form the components in more sophisticated techniques.</p>
<div class="section" id="sampling-from-discrete-distributions">
<h2>Sampling from Discrete Distributions<a class="headerlink" href="#sampling-from-discrete-distributions" title="Permalink to this headline">¶</a></h2>
<div class="section" id="uniform-continuous-to-uniform-discrete">
<h3>Uniform Continuous to Uniform Discrete<a class="headerlink" href="#uniform-continuous-to-uniform-discrete" title="Permalink to this headline">¶</a></h3>
<ul class="simple">
<li><p>In order to sample data from a particular distribution we can start with a uniform continuous distribution between 0 and 1 denoted as U[0,1]. The probability of picking a value less than ‘a’ that is between 0 and 1 is given by</p></li>
</ul>
<div class="math notranslate nohighlight">
\[P(x &lt; a) = a\]</div>
<p>       but because there are infinite possibilities between 0 and 1, the probability of picking any particular value ‘a’ is close to 0.</p>
<ul class="simple">
<li><p>If we wanted an arbitrary continuous distribution U[0,k], multiply U[0,1] by k to obtain the scaled distribution</p></li>
<li><p>If we have a discrete uniform distribution from 0 to ‘n’ denoted as U{0,1,…n-1}, this set has ‘n’ samples and the probability of choosing any discrete value ‘a’ is</p></li>
</ul>
<div class="math notranslate nohighlight">
\[P(x = a) = \dfrac{1}{n}\]</div>
<p>       since this is a discrete value and there are a finite number of elements in  this set. One way to convert this continuous uniform distribution U[0,1] to the        discrete distribution U{0,1,…n-1} is through the transformation X = [[n U]] where I have used the notation [[ ]] for rounding the values within to the nearest        integer. Now</p>
<div class="math notranslate nohighlight">
\[X \sim U \{0,1,...n-1\}\]</div>
</div>
<div class="section" id="arbitrary-non-uniform-discrete-distributions">
<h3>Arbitrary (Non-uniform) Discrete Distributions<a class="headerlink" href="#arbitrary-non-uniform-discrete-distributions" title="Permalink to this headline">¶</a></h3>
<p>To generate an arbitrary distribution, we can use the continuous uniform distribution and sample from it followed by a transform such that we get our desired distribution. In the figure below, we have divided the uniform continuous distribution U[0,1] into ‘n’ sections with uneven lengths, given by \(p_1, p_2, p_3…p_n\) (here n = 5) such that \(\sum p_i = 1\)</p>
<p><img alt="Interval Transformation" src="../_images/transformation.png" /></p>
<p>If we want to sample from a arbitrary discrete set \(A = {a_1, a_2…a_n}\), with probabilities given by \(p_1, p_2, p_3…p_n\) all we have to do is sample from the uniform continuous distribution U[0,1] since the interval \(i\) will be picked with probability \(p_i\) corresponding to the set element \(a_i\).</p>
</div>
</div>
<div class="section" id="the-inverse-transform-method">
<h2>The Inverse Transform Method<a class="headerlink" href="#the-inverse-transform-method" title="Permalink to this headline">¶</a></h2>
<p>This method uses the Cumulative Distribution Function (CDF) and the inverse of the CDF to generate our desired distribution.</p>
<p>If a variable ‘Y’ is generated by applying a function ‘F’ to ‘X’ we get</p>
<div class="math notranslate nohighlight">
\[Y = F(X)\]</div>
<p>which implies that we can apply an inverse transformation to ‘Y’, if it exists, to obtain ‘X’. Here the function  ‘F’ has to be invertible. The function ‘F’ is said to be bijective and has no jumps in its behavior.</p>
<div class="math notranslate nohighlight">
\[F^{-1} (Y) = X\]</div>
<p>The steps required to generate the new distribution from an existing distribution is shown below.</p>
<div class="section" id="derivation">
<h3>Derivation<a class="headerlink" href="#derivation" title="Permalink to this headline">¶</a></h3>
<p>If ‘y’ is a function of ‘z’, where</p>
<ul class="simple">
<li><p>the PDF of y is given by p(y) and</p></li>
<li><p>the PDF of z is given by p(z)</p></li>
</ul>
<div class="math notranslate nohighlight">
\[y = f(z)\]</div>
<p><em><strong>We want to determine the function f(z) such that the distribution of values ‘y’ formed by the transformation \( y = f(z)\) is our desired distribution.</strong></em></p>
<p>The distribution of ‘y’ will adhere to the following</p>
<div class="math notranslate nohighlight">
\[ p(y) = p(z) \lvert \dfrac{dz}{dy} \rvert\]</div>
<p>If ‘z’ has a uniform distribution this becomes</p>
<div class="math notranslate nohighlight">
\[p(y) = \lvert \dfrac{dz}{dy} \rvert\]</div>
<p>Integrating both sides, we get</p>
<div class="math notranslate nohighlight">
\[z = \int^y_{-\infty} p(y) dy = h(y)\]</div>
<p>If you look at the integral, it is simply the CDF of ‘y’, i.e. h(y) is the CDF of ‘y’. If we apply the inverse of the CDF function, i.e. \(h^{-1}\), on both sides we get</p>
<p><span class="math notranslate nohighlight">\(y = h^{-1} (z)\)</span></p>
<p>The purpose of this transformation is to express ‘y’ as a function of ‘z’. If we sample from the ‘z’ distribution, transform the values with the inverse of the CDF of the desired distribution (y), we get the values for ‘y’ which will have the desired distribution</p>
</div>
<div class="section" id="algorithm">
<h3>Algorithm<a class="headerlink" href="#algorithm" title="Permalink to this headline">¶</a></h3>
<ol>
<li><p>Calculate the inverse of the CDF of the desired distribution, given by \(F^{-1}\)</p></li>
<li><p>Sample from ‘z’ which is U[0,1]</p></li>
<li><p>Use the sampled values from (2) as input to the inverse of the CDF <span class="math notranslate nohighlight">\(F^{-1}\)</span> such that</p>
<div class="math notranslate nohighlight">
\[Y \sim F^{-1} (U)\]</div>
</li>
</ol>
<p>The limitation with this approach is that it must be possible to compute the inverse of the CDF of the distribution.</p>
</div>
<div class="section" id="example">
<h3>Example<a class="headerlink" href="#example" title="Permalink to this headline">¶</a></h3>
<p>An exponential distribution is given by the PDF</p>
<div class="math notranslate nohighlight">
\[p(y) = \lambda e^{-\lambda y}\]</div>
<p>if y &gt;= 0</p>
<p>The CDF for this distribution is given by</p>
<div class="math notranslate nohighlight">
\[F = 1 - e^{-\lambda y}\]</div>
<p>but</p>
<div class="math notranslate nohighlight">
\[ F = h(y) = z \longrightarrow z = 1 - e^{-\lambda y} \]</div>
<p>Taking the logarithm on both sides of the equation</p>
<div class="math notranslate nohighlight">
\[ y = -log(1 - z) / \lambda \]</div>
<p>Now if you sample from ‘z’ and plug those values into the equation above, you get values of ‘y’ which will have the desired distribution.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">from</span> <span class="nn">scipy.stats</span> <span class="kn">import</span> <span class="n">expon</span>
<span class="kn">from</span> <span class="nn">matplotlib</span> <span class="kn">import</span> <span class="n">pyplot</span> <span class="k">as</span> <span class="n">plt</span>

<span class="c1"># Generate random numbers</span>
<span class="n">U</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">5000</span><span class="p">)</span>
<span class="n">lam</span> <span class="o">=</span> <span class="mf">0.5</span>
<span class="n">X</span> <span class="o">=</span> <span class="o">-</span><span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="n">U</span><span class="p">)</span><span class="o">/</span><span class="n">lam</span> <span class="c1">#transformations</span>
<span class="n">hist</span><span class="p">,</span> <span class="n">bin_edges</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">histogram</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">bins</span><span class="o">=</span><span class="mi">20</span><span class="p">,</span> <span class="n">density</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span> <span class="c1">#histogram of the transformed variables</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">bin_edges</span><span class="p">[</span><span class="mi">0</span><span class="p">:</span><span class="o">-</span><span class="mi">1</span><span class="p">],</span> <span class="n">hist</span><span class="p">)</span> <span class="c1">#ideally should center the hist values to be the average of bin edges</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s2">&quot;Distribution generated using an Inverse Transform&quot;</span><span class="p">)</span>
<span class="c1"># Get analytical PDF</span>
<span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">()</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">16</span><span class="p">,</span> <span class="mi">1000</span><span class="p">)</span>
<span class="n">Y</span> <span class="o">=</span> <span class="n">expon</span><span class="o">.</span><span class="n">pdf</span><span class="p">(</span><span class="n">x</span><span class="p">,</span><span class="mi">0</span><span class="p">,</span><span class="mi">1</span><span class="o">/</span><span class="n">lam</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">Y</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s2">&quot;Analytical form of the desired Exponential distribution&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Text(0.5, 1.0, &#39;Analytical form of the desired Exponential distribution&#39;)
</pre></div>
</div>
<img alt="../_images/Sampling_4_1.png" src="../_images/Sampling_4_1.png" />
<img alt="../_images/Sampling_4_2.png" src="../_images/Sampling_4_2.png" />
</div>
</div>
</div>
</div>
<div class="section" id="ungraded-evaluation-30mins">
<h2>UNGRADED EVALUATION (30mins)<a class="headerlink" href="#ungraded-evaluation-30mins" title="Permalink to this headline">¶</a></h2>
<p>Generate a Rayleigh distribution using the Inverse Transform Method. The PDF of the Raleigh function f(x) is given by</p>
<p><span class="math notranslate nohighlight">\(f(x) = \dfrac{x}{\sigma^2} e^{-x^2 / 2\sigma^2}\)</span></p>
<p>when <span class="math notranslate nohighlight">\(x &gt; 0\)</span> and <span class="math notranslate nohighlight">\(\sigma\)</span> is the scale parameter. The CDF for the Rayleigh distribution is given by</p>
<p><span class="math notranslate nohighlight">\(F(x) = 1 - e^{-x^2 / 2\sigma^2}\)</span></p>
</div>
<div class="section" id="graded-evaluation-15-mins">
<h2>GRADED EVALUATION (15 mins)<a class="headerlink" href="#graded-evaluation-15-mins" title="Permalink to this headline">¶</a></h2>
<ol>
<li><p>Most real distributions are difficult to sample from with uniform sampling</p>
<p>a. True (C)</p>
<p>b. False</p>
</li>
<li><p>Uniform sampling is inefficient as the number of dimensions grow</p>
<p>a. True (C)</p>
<p>b. False</p>
</li>
<li><p>In high-dimensional spaces, most of the mass in the probability density is concentrated in a small region</p>
<p>a. True (C)</p>
<p>b. False</p>
</li>
<li><p>Ideally we want to sample from regions where the function f(x) and the probability density p(x) is high</p>
<p>a. True (C)</p>
<p>b. False</p>
</li>
<li><p>The Inverse Transform Method uses</p>
<p>a. The inverse of the PDF to generate our desired distribution</p>
<p>a. the inverse of the CDF to generate our desired distribution (C)</p>
</li>
</ol>
</div>
<div class="section" id="rejection-sampling">
<h2>Rejection Sampling<a class="headerlink" href="#rejection-sampling" title="Permalink to this headline">¶</a></h2>
<p>Rejection sampling is more sophisticated than the techniques listed above. It generates approximately the correct distribution, and rejection sampling is used to correct the errors introduced by the approximation resulting in the correct distribution. Rejection sampling is based on the following principles. Suppose that we want to sample from a distribution with density \(p(z)\).</p>
<ol class="simple">
<li><p>A probability density called the proposal density \(q(z)\). This density is selected such that it is easier to sample than the original distribution density \(p(z)\).</p></li>
<li><p>\(p(z)\) is difficult to sample from but we can evaluate it up to a certain proportionality constant.</p></li>
<li><p>A constant ‘k’ such that \(k q(z) &gt;= p(z)\) for all values of ‘z’. This forms an envelope around p(z) denoted by \(kq(z)\)</p></li>
</ol>
<p><img alt="Sampling" src="../_images/sampling_distribution.png" /></p>
<p>Given the above densities, we use the following steps</p>
<ol class="simple">
<li><p>Draw \(z_0\) from \(q(z)\) and compute \(k q(z_0)\)</p></li>
<li><p>Draw a uniform number \(u_0\) from \([0, k q(z_0)]\)</p></li>
<li><p>If \(u_0 &gt; p(z_0)\), the sample is rejected otherwise save \(u_0\). By doing so, anything that falls under \(p(z)\) is saved and has a uniform distribution thereby obtaining the distribution of \(p(z)\)</p></li>
<li><p>Continue with (1) until sufficient samples have been drawn</p></li>
</ol>
<p>The samples are accepted with probability \(\dfrac{p(z)}{k q(z)}\). For effective rejection sampling, we want the number of samples that are rejected to be minimal. This is possible only when the envelope distribution is close to the desired distribution. It is also inefficient to use in high dimensional spaces for the following reasons</p>
<ul class="simple">
<li><p>The ideal value of k in a ‘D’ dimensional space is given by \( (\dfrac{\sigma_q}{\sigma_p})^D\) where \(\sigma\) is the variance of either distribution.</p></li>
<li><p>The acceptance ratio for two normalized distributions with densities \(p(x)\) and \(q(x)\) is simply \(1/k\)</p></li>
<li><p>This acceptance ratio now scales as the ratio \( (\dfrac{\sigma_p}{\sigma_q})^D\). If \( \sigma_q\) is greater than \( \sigma_p\) by even 1%, for D = 1000 the acceptance ratio is now close to 1/20000.</p></li>
<li><p>In practical scenarios where the distributions are multimodal, this effect is exacerbated.</p></li>
</ul>
</div>
<div class="section" id="importance-sampling">
<h2>Importance Sampling<a class="headerlink" href="#importance-sampling" title="Permalink to this headline">¶</a></h2>
<p>Importance sampling is useful for computing terms such as the expectation of a function \(f(x)\) with distribution \(p(x)\). Ideally, we want to sample in space where the product \(f(x) p(x)\) is high since the expected value is computed for a discrete distribution as</p>
<div class="math notranslate nohighlight">
\[E[f] = \sum_i p(x_i) f(x_i)\]</div>
<p>Or, for a continuous distribution as</p>
<div class="math notranslate nohighlight">
\[E[f] = \int p(x) f(x) dx \]</div>
<p>Importance sampling is also based on the idea of using another proposal distribution that is easier to sample from, compared to the original distribution \(p(x)\).</p>
<p>$<span class="math notranslate nohighlight">\(E[f] = \int p(x) f(x) dx = \int \dfrac{p(x)}{q(x)} q(x) f(x) dx \approx \dfrac{1}{L} \sum_l^{drawn\;from\;Q(x)} \dfrac{p(x)}{q(x)} f(x) \)</span>$ where samples are drawn from q(x) instead of the difficult-to-sample-from distribution p(x).</p>
<p>The term \(\dfrac{p(x)}{q(x)}\) is known as the ‘importance weights’, and correct the bias resulting from sampling from the wrong distribution. Unlike rejection sampling, all samples are retained. Similar to rejection sampling, the envelope disribution should be close to the desired distribution for efficient sampling.</p>
</div>
<div class="section" id="id1">
<h2>GRADED EVALUATION (15 mins)<a class="headerlink" href="#id1" title="Permalink to this headline">¶</a></h2>
<ol>
<li><p>The rejection process in rejection sampling corrects the errors introduced by the approximation</p>
<p>a. True (C)</p>
<p>b. False</p>
</li>
<li><p>The proposal density is easier to sample than the desired distribution</p>
<p>a. True (C)</p>
<p>b. False</p>
</li>
<li><p>In rejection sampling, the proposal density ‘envelopes’ the desired distribution</p>
<p>a. True (C)</p>
<p>b. False</p>
</li>
<li><p>Importance sampling can be used to compute the expectation of a function f(x)</p>
<p>a. True (C)</p>
<p>b. False</p>
</li>
<li><p>In importance sampling</p>
<p>a. Some samples are retained</p>
<p>b. All samples are retained (C)</p>
</li>
</ol>
</div>
</div>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "sjster/statistical_computing_book",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            kernelName: "python3",
            path: "./docs"
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

              </div>
              
        </div>
    </div>
    
    
    <div class='prev-next-bottom'>
        
    <a class='left-prev' id="prev-link" href="Distributions.html" title="previous page">Introduction to Common Distributions</a>
    <a class='right-next' id="next-link" href="BayesianInference.html" title="next page">Topics in Model Performance</a>

    </div>
    <footer class="footer mt-5 mt-md-0">
    <div class="container">
      <p>
        
          By Srijith Rajamohan, Ph.D.<br/>
        
            &copy; Copyright 2020.<br/>
      </p>
    </div>
  </footer>
</main>


      </div>
    </div>

    
  <script src="../_static/js/index.d3f166471bb80abb5163.js"></script>


    
  </body>
</html>