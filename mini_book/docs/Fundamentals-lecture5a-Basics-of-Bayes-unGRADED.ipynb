{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction to the Bayes Theorem\n",
    "\n",
    "\n",
    "General references:\n",
    "  \n",
    "+ Statistical Inference (9780534243128): Casella, George, Berger, Roger L.  \n",
    "+ Probability Theory and Statistical Inference: Empirical Modeling with Observational Data (9781107185142): Spanos, A.  \n",
    "+ Bayesian Models: A Statistical Primer for Ecologists (9780691159287): Hobbs, N. Thompson, Hooten, Mevin B.  \n",
    "+ A First Course in Bayesian Statistical Methods (0387922997): Hoff, Peter D.\n",
    "  \n",
    "\n",
    "<br>\n",
    "<br>\n",
    "<hr style=\"border:2px solid blue\"> </hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bayes' Rule\n",
    "\n",
    "Starting from the rules of probability giving in the first section, we see that we can go from joint probabities to conditional via:\n",
    "\n",
    "$$P(A,B) = P(A|B) P(B)$$   \n",
    "\n",
    "There is no reason we can't do the same but reversing the conditioning:  \n",
    "\n",
    "$$P(A,B) = P(B|A) P(A)$$ \n",
    "\n",
    "Setting these two equal and solving for one of the two conditional probabilities, we get:  \n",
    "\n",
    "$$P(A|B) = \\frac{P(B|A)P(A)}{P(B)}$$\n",
    "\n",
    "This is known as Bayes' Rule.  \n",
    "\n",
    "Note that any combination of discrete and continous random variables can also be studies, for instance, assuming X is a discrete randcom variable and Y is a continuous random variable, and being verbose using probabilities for X and densities for Y, we would write this as:\n",
    "\n",
    "$$P(X=x|Y=y)=\\frac{f_{Y|X=x}(y)P(X=x)}{f_Y(y)}$$\n",
    "\n",
    "\n",
    "<br>\n",
    "<br>\n",
    "<hr style=\"border:2px solid blue\"> </hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bayes' rule for updating probabilities\n",
    "\n",
    "Suppose we are interested in taking a test to determine if we have a disease, COVID-19, for example.  As we take the test, we are told that in our area, 5% of the population has the disease.\n",
    "\n",
    "What is our probability of having the disease??  Without other information, we are just a random draw from the population, so 5% is a good guess.\n",
    "\n",
    "What information do we know?\n",
    "$$P(disease) = 0.05; P(\\overline{disease}) = 0.95$$\n",
    "\n",
    "Note: \\\\(\\overline{disease}\\\\) means, compliment or NOT disease.\n",
    "\n",
    "We then receive the results, the test comes back positive.  Are we in fact infected?  This question turns out to be less straight forward.  The reason this takes a bit more thought is the testing has error that needs to be accounted for.  The way to approach this question is through Bayes' Rule.\n",
    "\n",
    "What we want is the probabity we have disease given a positive test result:\n",
    "\n",
    "$$P(disease|+ test)$$\n",
    "\n",
    "Bayes' Rule then gives this as:\n",
    "\n",
    "$$P(disease|+ test) = \\frac{P(+ test|disease)P(disease)}{P(+ test)}$$\n",
    "\n",
    "What are \\\\(P(+ test|disease)\\\\) and \\\\(P(+ test)\\\\)?  The first, \\\\(P(+ test|disease)\\\\) is the sensitivity of the test, or *true positive rate*.  For one of the COVID-19 tests, the test sensitivity is reported to be 80%.  What about \\\\(P(+ test)\\\\)?  Using the law of total probability, we are able to partition that into something more recognizable:\n",
    "\n",
    "$$P(+test) = P(+test|disease)P(disease) + P(+test|\\overline{disease})P(\\overline{disease})$$\n",
    "\n",
    "$$P(disease|+ test) = \\frac{P(+ test|disease)P(disease)}{P(+test|disease)P(disease) + P(+test|\\overline{disease})P(\\overline{disease})}$$\n",
    "\n",
    "Partitioning like this, we see we need one more item of information: \\\\(P(+test|\\overline{disease})\\\\) which is the *false positive rate*.  Tests usually report thier specificity, which is the *true negative rate* (\\\\(P(-test|\\overline{disease})\\\\) = ) rather than the FPR, so we need to convert:\n",
    "\n",
    "$$P(+test|\\overline{disease}) = 1 - P(-test|\\overline{disease}) = 1 - 0.989 = 0.011$$ \n",
    "\n",
    "We can now answer our question:\n",
    "\n",
    "$$P(disease|+ test) = \\frac{0.8 \\ast 0.05}{0.8\\ast 0.05 + 0.011 \\ast 0.95} = 0.79$$\n",
    "\n",
    "Not 100%, but still high at 79%.\n",
    "\n",
    "<br>\n",
    "<br>\n",
    "<hr style=\"border:2px solid blue\"> </hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Breaking down Bayes' Rule\n",
    "\n",
    "Let's go through the parts of Bayes' Rule.  We will go through this more completely in another section.\n",
    "\n",
    "$$P(A|B) = \\frac{P(B|A)P(A)}{P(B)}$$\n",
    "\n",
    "#### Posterior\n",
    "\n",
    "The \\\\(P(A|B)\\\\) on the left hand side is termed the posterior.  It is the probabillity or likelihood of A, given B is true.  As we will see, in Bayesian analysis, we are often looking for the posterior to represent the distribution of the parameter given data.\n",
    "\n",
    "#### Likelihood\n",
    "\n",
    "The term, \\\\(P(B|A)\\\\), is the likelihood.  In our disease example above, this was the probability of a positive test, given disease.  In future problems, we will be more interested in inference of parameters given data, such that the likelihood will represent the likelihood of observing the data given parameters.\n",
    "\n",
    "#### Priors\n",
    "\n",
    "\\\\(P(A)\\\\) is called the prior.  In the above example, this reflected our prior knowledge.  Before collecting (new) data, we had some notion of our probability of having disease.  It can represent a belief, it can be informed, or vague.\n",
    "\n",
    "Above, we used a probabillity, the probabillity of diseased based on the population was set to 5%.  We could have changed the prior to use a distributions, perhaps we had data of surrounding counties and knew the average was 5% with a defined variance.  Priors can also be used to induce a known distribution in the posterior.\n",
    "\n",
    "#### Marginal\n",
    "\n",
    "The denominator, \\\\(P(B)\\\\), is the marginal probability of B.  This is a constant and in many analysis may be dropped.  \n",
    "\n",
    "Using these terms, Bayes' Rule can be writen:\n",
    "\n",
    "$$posterior = \\frac{likelihood \\ast prior}{marginal}$$\n",
    "\n",
    "<br>\n",
    "<br>\n",
    "<hr style=\"border:2px solid blue\"> </hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GRADED EVALUATION (15 mins)\n",
    "\n",
    "1.  A car repair shop receives a car with reports of strange noises coming from the engine.  The shop knows 90% of the cars that come in for \"noises\" have a loose fan belt while the other 10% have a loose muffler.  A common description, 95%, of cars having loose mufflers is they rattle.  Less commonly, 8%, fan belt issues can also sound like a rattle.  The car owner is describing the strange noise as a rattle.  What is the probability the car has a loose muffler?\n",
    "\n",
    "    a. 78%  \n",
    "    \n",
    "    b. 57%     \n",
    "    \n",
    "    c. 95%   \n",
    "\n",
    "\n",
    "2. It is estimated that 80% of emails are spam.  You have developed a new algorithm to detect spam.  Your spam software can detect 99% of spam emails but has a false positive rate of 5%.  Your company receives 1000 emails in a day, how many emails will be incorrectly marked as spam?\n",
    " \n",
    "    a. 10       \n",
    "    \n",
    "    b. 20  \n",
    "    \n",
    "    c. 5  \n",
    "    \n",
    "    d. 200\n",
    "    \n",
    "    e. 50\n",
    "\n",
    "\n",
    "3.  You have developed a new algorithm for detecting fraud.  It has a sensitivity of 90% with a specificity of 95%.  Choose the correct statement:\n",
    "\n",
    "    a. true positive rate = 90%, true negative rate = 5% \n",
    "    \n",
    "    b. true positive rate = 90%, true negative rate = 95%       \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
